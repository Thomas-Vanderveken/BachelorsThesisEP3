% Encoding: UTF-8
@book{Knuth1998,
 author = {Knuth, Donald E.},
 title = {The art of computer programming,  volume 3: (2nd ed.) sorting and searching},
 year = {1998},
 publisher = {Addison Wesley Longman Publishing Co., Inc.},
 address = {Redwood City, CA, USA}
}

@book{Pollefliet2011,
  author = {Pollefliet, Leen},
  title = {Schrijven van verslag tot eindwerk: do's en don'ts},
  year = {2011},
  publisher = {Academia Press},
  address = {Gent}
}

@article{Creeger2009,
  author = {Creeger, Mache},
  journal = {Communications of the ACM},
  number = {8},
  pages = {50--56},
  title = {{CTO Roundtable: Cloud Computing}},
  volume = {52},
  year = {2009}
}

@Comment{jabref-meta: databaseType:biblatex;}

@misc{SECform13F2024,
  author       = {U.S. Securities and Exchange Commission},
  title        = {Frequently Asked Questions About Form 13F},
  howpublished = {\url{https://www.sec.gov/divisions/investment/13ffaq}},
  note         = {Accessed: 2024-08-08},
  year         = {2024}
}

@misc{IBM2024,
  author = {IBM},
  title = {What is text-mining},
  howpublished = {\url{https://www.ibm.com/topics/text-mining}},
  note = {accessed: 2024-08-08},
  year = {2024}

}
@misc{AWS2024,
  author = {AWS},
  title = {What is the difference between structured and unstructured data?},
  howpublished = {\url{https://aws.amazon.com/compare/the-difference-between-structured-data-and-unstructured-data/}},
  note = {accessed: 2024-08-09},
  year = {2024}

}
@misc{SC2024,
  author = {SaturnCLoud},
  title = {Stemming in Natural Language Processing},
  howpublished = {\url{https://saturncloud.io/glossary/stemming/}},
  note = {accessed: 2024-08-10},
  year = {2024}

}
@misc{Kinter2024,
  author = {Patrick Kinter},
  title = {Text mining: applications and techniques},
  howpublished = {\url{https://www.alexanderthamm.com/en/blog/text-mining-basics-methods-and-application-cases/}},
  note = {accessed: 2024-08-09},
  year = {2024}

}


@article{gaikwad2014text,
  title={Text mining methods and techniques},
  author={Gaikwad, Sonali Vijay and Chaugule, Archana and Patil, Pramod},
  journal={International Journal of Computer Applications},
  doi={10.5120/14937-3507},
  volume={85},
  number={17},
  year={2014},
  publisher={Foundation of Computer Science}
}

@article{Gupta2020,
  author    = {Aaryan Gupta and Vinya Dengre and Hamza Abubakar Kheruwala and Manan Shah},
  title     = {Comprehensive review of text-mining applications in finance},
  journal   = {Financial Innovations},
  volume    = {6},
  number    = {1},
  pages     = {39},
  year      = {2020},
  doi       = {10.1186/s40854-020-00205-1},
  url       = {https://doi.org/10.1186/s40854-020-00205-1}
}

@article{MEDHAT20141093,
title = {Sentiment analysis algorithms and applications: A survey},
journal = {Ain Shams Engineering Journal},
volume = {5},
number = {4},
pages = {1093-1113},
year = {2014},
issn = {2090-4479},
doi = {https://doi.org/10.1016/j.asej.2014.04.011},
url = {https://www.sciencedirect.com/science/article/pii/S2090447914000550},
author = {Walaa Medhat and Ahmed Hassan and Hoda Korashy},
keywords = {Sentiment analysis, Sentiment classification, Feature selection, Emotion detection, Transfer learning, Building resources},
abstract = {Sentiment Analysis (SA) is an ongoing field of research in text mining field. SA is the computational treatment of opinions, sentiments and subjectivity of text. This survey paper tackles a comprehensive overview of the last update in this field. Many recently proposed algorithms' enhancements and various SA applications are investigated and presented briefly in this survey. These articles are categorized according to their contributions in the various SA techniques. The related fields to SA (transfer learning, emotion detection, and building resources) that attracted researchers recently are discussed. The main target of this survey is to give nearly full image of SA techniques and the related fields with brief details. The main contributions of this paper include the sophisticated categorizations of a large number of recent articles and the illustration of the recent trend of research in the sentiment analysis and its related areas.}
}
@article{Talib2016TextMining,
  title = {Text Mining: Techniques, Applications and Issues},
  author = {Ramzan Talib and Muhammad Kashif Hanif and Shaeela Ayesha and Fakeeha Fatima},
  journal = {{International Journal of Advanced Computer Science and Applications (IJACSA)}},
  volume = {7},
  number = {11},
  year = {2016},
  url = {https://doi.org/10.14569/IJACSA.2016.071107},
}

@article{Krallinger2024, 
  author = {Krallinger, M. and Rabal, O. and Lourenço, A. and Oyarzábal, J. and Valencia, A.}, 
  title = {Information retrieval and text mining technologies for chemistry}, 
  journal = {Chemical Reviews}, 
  year = {2017}, 
  volume = {117}, 
  issue = {12}, 
  pages = {7673-7761}, 
  doi = {10.1021/acs.chemrev.6b00851} 
}
@misc{Javija2024,
  author       = {Rushi Javija},
  note         = {16-07-2024},
  editor       = {GeeksForGeeks},
  title        = {Difference between Information Retrieval and Information Extraction},
  year         = {2024},
  accessed = {10/08/2024}

}
@article{CAI201870,
title = {Feature selection in machine learning: A new perspective},
journal = {Neurocomputing},
volume = {300},
pages = {70-79},
year = {2018},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2017.11.077},
url = {https://www.sciencedirect.com/science/article/pii/S0925231218302911},
author = {Jie Cai and Jiawei Luo and Shulin Wang and Sheng Yang},
keywords = {Feature selection, Dimensionality reduction, Machine learning, Data mining},
abstract = {High-dimensional data analysis is a challenge for researchers and engineers in the fields of machine learning and data mining. Feature selection provides an effective way to solve this problem by removing irrelevant and redundant data, which can reduce computation time, improve learning accuracy, and facilitate a better understanding for the learning model or data. In this study, we discuss several frequently-used evaluation measures for feature selection, and then survey supervised, unsupervised, and semi-supervised feature selection methods, which are widely applied in machine learning problems, such as classification and clustering. Lastly, future challenges about feature selection are discussed.}
}
@article{Mustazzihim,
  author = {Mustazzihim, Suhaidi en Rabiah Abdul Kadir enSabrina Tiun},
  year = {2021},
  title={A REVIEW OF FEATURE EXTRACTION METHODS ON MACHINE LEARNING}, 
  volume={6}, 
  url={https://gaexcellence.com/index.php/jistm/article/view/1125}, 
  number={22}, 
  journal={JOURNAL INFORMATION AND TECHNOLOGY MANAGEMENT JISTM}, 
  author={Mustazzihim Suhaidi and Rabiah Abdul Kadir and Sabrina Tiun}, 
  year={2021}, 
  pages={51–59} 
}

@misc{vajjala2022reallyknowstateart,
  title={What do we Really Know about State of the Art NER?}, 
  author={Sowmya Vajjala and Ramya Balasubramaniam},
  year={2022},
  url={https://arxiv.org/abs/2205.00034}, 
  doi = {https://doi.org/10.48550/arXiv.2205.00034 }
}
@misc{Martinez2024,
  title={Part-of-speech tagging}, 
  author={Angel R. Martinez},
  year={2012},
  doi = {https://doi.org/10.1002/wics.195 },
  note = {WIREs Comp Stat 2012, 4:107–113. doi: 10.1002/wics.195}
}

@manual{spacyff,
  author       = {Spacy},
  title        = {Facts & Figures},
  year         = {},
  url={https://arxiv.org/abs/2205.00034}, 

}

@article{amade2024automatic,
  title={Automatic Text Summarization Using NLTK \& Spacy},
  author={Amade, Divya and Chandra, Rashmi and Sinha, Vivek Kumar and Anand, Divya},
  year={2024},
  month={February 28},
  note={Available at SSRN: \url{https://ssrn.com/abstract=4742012} or \url{http://dx.doi.org/10.2139/ssrn.4742012}}
}

@article{khan2023performance,
  title={SQL and NoSQL Database Software Architecture Performance Analysis and Assessments—A Systematic Literature Review},
  author={Khan, Wisal and Kumar, Teerath and Zhang, Cheng and Raj, Kislay and Roy, Arunabha M. and Luo, Bin},
  journal={Big Data Cogn. Comput.},
  volume={7},
  number={2},
  pages={97},
  year={2023},
  doi={10.3390/bdcc7020097},
  note={Submission received: 13 January 2023 / Revised: 6 May 2023 / Accepted: 8 May 2023 / Published: 12 May 2023},
}